---
title : "How to use hurdled lognormal likelihood to model outcomes in R?"
author : "Suhishan Bhandari"
toc : TRUE
fontsize : 20px,
fontfamily: OpenSans
---

```{r, include = FALSE}
library(tidyverse)
library(brms)
library(patchwork)

theme_set(theme_minimal(base_size = 16))
  
```

# Introduction

While working on a research project, I had to model *total hours worked*, which is a continuous metric that can be assumed to be normal, but with a sizable chunk of zeros as well. These values are all constrained to be positive because they are hours worked in the last 7 days. The problem is that in a standard OLS model, the outcome variable can take all possible real values, and even if I log the variable for positivity constraint, I am still left with the problem of modelling a sizable chunk of zeros that is expected when surveying people on their self-reported work hours. 

Let's look at this with an example. Here, I simulate 250 observations of *work hours* as a log normal process with 15% of these values being 0 hours worked. 

```{r}
N <- 1e3 #1e3 observations

d <- tibble(
  isZero = rbinom(N, 1, 0.15), #15% 0 observations
  wh = ifelse(isZero == 1, 0, rlnorm(N, 3.5, 0.4))
) 

d %>% 
  ggplot(aes(wh)) + 
  geom_histogram(bins = 40, fill = "skyblue2", color = "black")+
  labs(x = "Work Hours")

```
Using a log normal distribution with the mean of around exp(3.5), we get a distribution of work hours that matches closely with reality. As we can see, if we assume 15% of people surveyed to report 0 hours worked, we are now working with a symmetric distribution that is bounded to be greater than 0 but is zero-inflated. While zero-inflated models are common for binomial or poisson processes, it is much harder to find and model variables that are zero-inflated while being continuous.

# Modelling

Let's take a peek at our model. We are assuming that wh is log normally distributed, which means that log(wh) is normally distributed. The model contains two parts. The first is only for the values of not being zero, that is the mu part. The second hu intercept is for the probability of a zero. 

The prior is normal(3, 0.5) because we assume before looking at the data that the log(wh) is normal and as such, the non-zero part of it is going to follow a normal distribution.

```{r, output = FALSE}
model_1 <- brm(
  data = d,
  family = hurdle_lognormal,
  bf(wh ~ 1,
     hu ~ 1),
  prior = c(
    prior(normal(3, 0.5), class = Intercept, lb = 0),
    prior(normal(-1, 1), dpar = "hu", class = Intercept),
    prior(exponential(4), class = sigma)
  ),
  iter = 2e3, warmup = 1e3, chains = 4, cores = 4,
  sample_prior = T,
  file = "fits/model_1"
)

```

Prior Predictive Simulation

```{r, fig.width=13}
tibble(
  Intercept = rnorm(N, 3, 0.5),
  sigma = rexp(N, 4)
) %>% 
  ggplot(aes(x = exp(Intercept + (sigma^2)/2)))+
  geom_histogram(bins = 100)+
  coord_cartesian(xlim = c(0, 100))
```
Prior Predictive Simulation for the hurdle:

```{r, fig.width=13}
tibble(
  o = rnorm(N, -1, 1),
  probs = inv_logit_scaled(o)
) %>% 
  ggplot(aes(x = probs))+
  geom_histogram(bins = 100)


```

Now, let's look at the model fit.

```{r}
posterior_summary(model_1)[1:3, ] %>% 
  round(digits = 3)
```
In the original scale.

The Model for work hours > 0

```{r}
wh_posterior_1 <- as_draws_df(model_1) %>% 
  mutate(work_hours = exp(b_Intercept + (sigma ^2) / 2)) %>% 
  ggplot(aes(x = work_hours))+
  geom_density()
```

Model for the hurdle intercept i.e. the probability of zero.

```{r}
hu_posterior_1 <- as_draws_df(model_1) %>% 
  mutate(probability  = inv_logit_scaled(b_hu_Intercept)) %>% 
  ggplot(aes(x = probability))+
  geom_density()


```

Both Figures side by side.

```{r, fig.width=14}
(wh_posterior_1 | hu_posterior_1)
```

# Group-Wise Interaction Effect.

Suppose that average work hours differs by groups, may it be geographical or at different times. Think of a scenario of a treatment and a control, measure before and after certain labor market shock. Let's assume two neighbouring districts A and B, whereby A experience war at time period t and B didn't. Let's assume we have data for A and B before the war occurred, and the data for work hours after the war occurred. Let's assume the data is repeated cross section data. We can simulate it as follows:

```{r}
a_0 <-  3.7
a_post <-  -0.05
a_treat <-  -0.05
a_pt <- -0.2

g <- tibble(
  post = rep(c(0, 1), each = 500), # time period 0 is before and time period 1 is after.
  treat = rep(c(0, 1), times = 500 ), # 0 is no-war, 1 is war.
  isZero = rbinom(N, 1, prob = 0.1 + 0.07 * post  +  #0.07 because of temporary immigration
                    (0.03) * treat + 0.1 * (post * treat)),
  
  wh = (1 - isZero) * rlnorm(N, a_0 + a_post * post + 
                               a_treat * treat + a_pt * (post * treat),
                             sdlog = 0.4)
)



```

4 groups:

1 : Post = 0, Treat = 0
2 : Post = 1, Treat = 1
3 : Post = 0, Treat = 1
4 : Post = 1, Treat = 1

```{r}
g <- g %>% mutate(
  group = factor(1 + post + 2 * treat, 
                 labels = c("Pre-Control", "Post-Control",
                            "Pre-Treatment","Post-Treatment"))
)

```


Let's look at what we simulated:

```{r}
g %>% 
  group_by(group) %>% 
  summarize(avg_wh = mean(wh)) %>% 
  ggplot(aes(x = group, y = avg_wh))+
  geom_linerange(aes(ymin = 0, ymax = avg_wh),color = "black",
           linewidth = 1)

g %>% 
  group_by(group) %>% 
  summarize(avg_isZero = mean(isZero)) %>% 
  ggplot(aes(x = group, y = avg_isZero))+
  geom_linerange(aes(ymin = 0, ymax = avg_isZero),color = "black",
           linewidth = 1)


```

## OLS Model 

```{r}
# A normal OLS model.

ols_group <- lm(wh ~ 0 + group, data = g)
summary(ols_group)

```

Because the mean also counts and includes zeros, everything is muddled in. It's fine here where we can see that after the war, the war-trodden district both had lower work hours and more unemployment, but in cases where these two phenomena have different causes, or if war affects people in different ways, this analysis may lead us astray. 
