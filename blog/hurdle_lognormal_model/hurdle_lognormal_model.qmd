---
title : "How to use hurdled lognormal likelihood to model outcomes in R?"
author : "Suhishan Bhandari"
toc : TRUE
fontsize : 20px,
fontfamily: OpenSans
---

```{r, include = FALSE}
library(tidyverse)
library(brms)
library(patchwork)

theme_set(theme_minimal(base_size = 20))
  
```

# Introduction

While working on a research project, I had to model people's work hours: the survey asked people to self-report how many hours they spent working in the past 7 days. There are multiple constraints to the seemingly innocent *work hours*:

1.  It is naturally bounded to be positive.
2.  While people report their answers in integers, the variable seems clearly continuous.
3.  The variable tends to have a clear spike at and around zero. This is because there are multiple causes of economic inactivity such as unemployment, student and pensioner population, voluntary vacations and so on.

The most distinguishing feature of a variable such as `work hours` is that it arises out of at least two generating processes. It is plausible to assume that there is one process that determines average incidence of observed 0s, and another one that determines average *non-zero* *`work hours`.* This is precisely what fascinated me about this variable and why I figured that a Bayesian approach, specifically `brms` 's `hurdle_lognormal` model may be better suited for inference.

The Objectives of this article are:

1.  Understand why a `hurdle_lognormal` likelihood suits the constraints that we have to work with.
2.  Simulate data and model probability of `hurdle` 0 and average non-zero `work hours` simultaneously in a single model.
3.  Include covariates and see why modelling the two separate phenomena aids in inference.

# Hurdle Lognormal Likelihood

## Data Simulation

Let's look at this with an example. Here, I simulate $1000$ observations of `work hours` as a lognormal process with 15% of these values being 0 hours worked.

```{r}
N <- 1e3 #1000 observations

d <- tibble(
  isZero = rbinom(N, 1, 0.15), #15% 0 observations
  wh = (1 - isZero) *rlnorm(N, 3.5, 0.4)
) 

d %>% 
  ggplot(aes(wh)) + 
  geom_histogram(bins = 40, fill = "skyblue2", color = "black")+
  labs(x = "Work Hours")

```

In our data simulation, we can see that Work Hours `wh` is a function of `isZero` i.e. the probability of seeing zero, and if not $0$, a log normal process with $\mu_{log} = 3.5$ and $\sigma_{log}=0.4$. This results in a variable `wh` which contains around $15 \%$ zeros and average non-zero work hours of $exp(\mu_{log} + \frac{\sigma_{log}^2}{2})$.

```{r}
mean(d$isZero)

# Theoretical mean of non-zero work hours:
exp(3.5 + (0.4^2)/2)

# Actual mean of non-zero work hours:
mean(d$wh[d$isZero == 0])
```

# Intercept-only model.

`model_1` is our first brms model and the parameters of our interest are:

1.  Average Work Hours for people who worked at least 1 hour.
2.  Standard deviation of work hours for people who worked at least 1 hour.
3.  The probability of observing the `hurdle` i.e. $0$.

```{r, output = FALSE}
model_1 <- brm(
  data = d,
  family = hurdle_lognormal,
  bf(wh ~ 1,
     hu ~ 1),
  prior = c(
    prior(normal(3.5, 0.5), class = Intercept, lb = 0),
    prior(normal(-1, 1), dpar = "hu", class = Intercept),
    prior(exponential(4), class = sigma)
  ),
  iter = 2e3, warmup = 1e3, chains = 4, cores = 4,
  sample_prior = T,
  file = "fits/model_1"
)

```

## Prior Predictive Simulation

Before we see the results, let's first look at the prior predictive simulation for average non-zero work hours and the probability of hurdle. Before we look at the data, the model expects average non-zero work hours to be around $exp(3.5 + \frac{0.25^2}{2}) = 34.16$ hours where the two parameters that define this being the `Intercept` and `sigma(sd)` of `log(wh)`.

```{r, fig.width=13}
tibble(
  Intercept = rnorm(N, 3.5, 0.5),
  sigma = rexp(N, 4)
) %>% 
  ggplot(aes(x = exp(Intercept + (sigma^2)/2)))+
  geom_histogram(bins = 100, fill = "brown", color = "black",
                 alpha = 1/2)+
  coord_cartesian(xlim = c(0, 110))
```

As for the probability of observing a $0$, the model expects most of the probability mass around `inv_logit_scaled(-1)` = $0.27$ i.e $27\%$.

```{r, fig.width=13}
tibble(
  o = rnorm(N, -1, 1),
  probs = inv_logit_scaled(o)
) %>% 
  ggplot(aes(x = probs))+
  geom_histogram(bins = 50, fill = "brown", color = "black",
                 alpha = 1/2)


```

## Model-fit.

Now, let's look at the model fit.

```{r}
posterior_summary(model_1)[1:3, ] %>% 
  round(digits = 3)
```

```{r}
# Work Hours Posterior
wh_posterior_1 <- as_draws_df(model_1) %>% 
  mutate(
    work_hours = exp(b_Intercept + (sigma ^2) / 2) # turning parameters into original scale
    ) %>% 
  ggplot(aes(x = work_hours))+
  geom_density(linewidth = 2)

# Hurdle Posterior.
hu_posterior_1 <- as_draws_df(model_1) %>% 
  mutate(
    probability  = inv_logit_scaled(b_hu_Intercept)
    ) %>% 
  ggplot(aes(x = probability))+
  geom_density(linewidth = 2)

```

Both Figures side by side.

```{r, fig.width=14}
(wh_posterior_1 | hu_posterior_1)
```

As expected, the model's results matches closely with the sample average work hours of around $35$ hours  and the $15%$ probability of observing a $0$. However, this is different to a standard OLS result, where the separation of both phenomena require two separate models and two separate regressions.

```{r}
# Overall OLS
lm(wh ~ 1, data = d)[1]

# only for non-zero work Hours
lm(wh ~ 1, data = d[d$wh > 0,])[1]

# probability of zero.
lm(isZero ~ 1, data = d)[1]
```



# Group-Wise Interaction Effect.

Suppose that average work hours differs by groups, may it be geographical or at different times. Think of a scenario of a treatment and a control, measure before and after certain labor market shock. Let's assume two neighbouring districts A and B, whereby A experience war at time period t and B didn't. Let's assume we have data for A and B before the war occurred, and the data for work hours after the war occurred. Let's assume the data is repeated cross section data. We can simulate it as follows:

```{r}
a_0 <-  3.7
a_post <-  -0.05
a_treat <-  -0.05
a_pt <- -0.2

g <- tibble(
  post = rep(c(0, 1), each = 500), # time period 0 is before and time period 1 is after.
  treat = rep(c(0, 1), times = 500 ), # 0 is no-war, 1 is war.
  isZero = rbinom(N, 1, prob = 0.1 + 0.07 * post  +  #0.07 because of temporary immigration
                    (0.03) * treat + 0.1 * (post * treat)),
  
  wh = (1 - isZero) * rlnorm(N, a_0 + a_post * post + 
                               a_treat * treat + a_pt * (post * treat),
                             sdlog = 0.4)
)



```

4 groups:

1 : Post = 0, Treat = 0 2 : Post = 1, Treat = 1 3 : Post = 0, Treat = 1 4 : Post = 1, Treat = 1

```{r}
g <- g %>% mutate(
  group = factor(1 + post + 2 * treat, 
                 labels = c("Pre-Control", "Post-Control",
                            "Pre-Treatment","Post-Treatment"))
)

```

Let's look at what we simulated:

```{r}
g %>% 
  group_by(group) %>% 
  summarize(avg_wh = mean(wh)) %>% 
  ggplot(aes(x = group, y = avg_wh))+
  geom_linerange(aes(ymin = 0, ymax = avg_wh),color = "black",
           linewidth = 1)

g %>% 
  group_by(group) %>% 
  summarize(avg_isZero = mean(isZero)) %>% 
  ggplot(aes(x = group, y = avg_isZero))+
  geom_linerange(aes(ymin = 0, ymax = avg_isZero),color = "black",
           linewidth = 1)


```

## OLS Model

```{r}
# A normal OLS model.

ols_group <- lm(wh ~ 0 + group, data = g)
summary(ols_group)

```

Because the mean also counts and includes zeros, everything is muddled in. It's fine here where we can see that after the war, the war-trodden district both had lower work hours and more unemployment, but in cases where these two phenomena have different causes, or if war affects people in different ways, this analysis may lead us astray.

## Group_wise interaction brms model.

```{r}
model_2 <- brm(
  data = g,
  family = hurdle_lognormal,
  bf(wh ~ 0 + group,
      hu ~ 0 + group),
  prior = c(
    prior(normal(3, 0.5), class = b, lb = 0),
    prior(normal(-1, 1), dpar = "hu", class = b),
    prior(exponential(4), class = sigma)
  ),
  sample_prior = T,
  iter = 2000, warmup = 1000, chains = 4, cores = 4,
  file = "fits/model_2"
)

```
